{"cells":[{"cell_type":"markdown","metadata":{"id":"vw1YGA9Wl4VW"},"source":["# Setup"]},{"cell_type":"code","execution_count":64,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":966,"status":"ok","timestamp":1709936747978,"user":{"displayName":"Qilin Zhou","userId":"10885857608007718413"},"user_tz":360},"id":"0qULNy3-l0aQ","outputId":"fa456e30-e6a6-49f4-c785-d386e5331de2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","\n","drive.mount(\"/content/gdrive/\")"]},{"cell_type":"code","execution_count":65,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1709936747978,"user":{"displayName":"Qilin Zhou","userId":"10885857608007718413"},"user_tz":360},"id":"tg9qCyQRl2Zs","outputId":"55316911-766f-4c9d-8f03-b64c8a68c3a1"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/gdrive/MyDrive/ML/ML-9\n"]}],"source":["%cd /content/gdrive/MyDrive/ML/ML-9"]},{"cell_type":"markdown","metadata":{"id":"kRjeCR5LmLI2"},"source":["# Assignment 9, Qilin Zhou, 2024-03-08"]},{"cell_type":"markdown","metadata":{"id":"tG3Sb0U0mOoK"},"source":["## Question 1: Train an Encoder-Decoder model that can convert a date string from one format - April 22, 2019 - to another format - 2019-04-22"]},{"cell_type":"code","execution_count":75,"metadata":{"executionInfo":{"elapsed":313,"status":"ok","timestamp":1709937406276,"user":{"displayName":"Qilin Zhou","userId":"10885857608007718413"},"user_tz":360},"id":"2HdxJLfCmM7a"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, TimeDistributed\n","from datetime import datetime, timedelta\n","import random\n","\n","tf.random.set_seed(42)\n","random.seed(42)\n","np.random.seed(42)"]},{"cell_type":"markdown","metadata":{"id":"zKdRArdv2yx5"},"source":["### Generate the dataset"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":130,"status":"ok","timestamp":1709933861297,"user":{"displayName":"Qilin Zhou","userId":"10885857608007718413"},"user_tz":360},"id":"hV0jiISo2xUQ"},"outputs":[],"source":["def generate_random_date(start_date, end_date):\n","    random_num_days = random.randrange((end_date - start_date).days)\n","    random_date = start_date + timedelta(days=random_num_days)\n","    return random_date.strftime(\"%B %d, %Y\"), random_date.strftime(\"%Y-%m-%d\")\n","\n","\n","def create_date_dataset(number_of_samples=20000):\n","    start_date = datetime(1900, 1, 1)\n","    end_date = datetime(2024, 3, 8)\n","    return [\n","        generate_random_date(start_date, end_date) for _ in range(number_of_samples)\n","    ]"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":292,"status":"ok","timestamp":1709933863024,"user":{"displayName":"Qilin Zhou","userId":"10885857608007718413"},"user_tz":360},"id":"BtkUryJD3Y7v"},"outputs":[],"source":["date_dataset = create_date_dataset()"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":133,"status":"ok","timestamp":1709934715227,"user":{"displayName":"Qilin Zhou","userId":"10885857608007718413"},"user_tz":360},"id":"MeHnLo78DMjE"},"outputs":[],"source":["x, y = zip(*date_dataset)"]},{"cell_type":"markdown","metadata":{"id":"FAbbPQRn4Kwo"},"source":["### Create a basic Encoderâ€“Decoder model with preprocessed inputs"]},{"cell_type":"code","execution_count":97,"metadata":{"executionInfo":{"elapsed":148,"status":"ok","timestamp":1709939850646,"user":{"displayName":"Qilin Zhou","userId":"10885857608007718413"},"user_tz":360},"id":"nme8UqXJEK-s"},"outputs":[],"source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing.text import Tokenizer"]},{"cell_type":"code","execution_count":115,"metadata":{"executionInfo":{"elapsed":1291,"status":"ok","timestamp":1709941376024,"user":{"displayName":"Qilin Zhou","userId":"10885857608007718413"},"user_tz":360},"id":"6BoySc2dEG0M"},"outputs":[],"source":["input_texts, target_texts = zip(*date_dataset)\n","\n","target_texts = [\"\\t\" + text + \"\\n\" for text in target_texts]\n","\n","tokenizer = Tokenizer(char_level=True)\n","tokenizer.fit_on_texts(list(input_texts) + list(target_texts))\n","vocab_size = len(tokenizer.word_index) + 1\n","\n","input_sequences = tokenizer.texts_to_sequences(input_texts)\n","target_sequences = tokenizer.texts_to_sequences(target_texts)\n","\n","# Pad sequences for consistent length\n","max_encoder_seq_length = max([len(txt) for txt in input_sequences])\n","max_decoder_seq_length = max([len(txt) for txt in target_sequences])\n","\n","encoder_input_data = pad_sequences(\n","    input_sequences, maxlen=max_encoder_seq_length, padding=\"post\"\n",")\n","decoder_input_data = pad_sequences(\n","    [seq[:-1] for seq in target_sequences],\n","    maxlen=max_decoder_seq_length,\n","    padding=\"post\",\n",")\n","decoder_target_data = pad_sequences(\n","    [seq[1:] for seq in target_sequences], maxlen=max_decoder_seq_length, padding=\"post\"\n",")"]},{"cell_type":"code","execution_count":116,"metadata":{"executionInfo":{"elapsed":648,"status":"ok","timestamp":1709941377119,"user":{"displayName":"Qilin Zhou","userId":"10885857608007718413"},"user_tz":360},"id":"MSqk29Eo-HtK"},"outputs":[],"source":["embedding_size = 32\n","encoder_seq_length = max_encoder_seq_length\n","decoder_seq_length = max_decoder_seq_length\n","\n","# encoder\n","encoder_inputs = Input(\n","    shape=(encoder_seq_length,), dtype=\"int32\", name=\"encoder_inputs\"\n",")\n","encoder_embedding = Embedding(\n","    input_dim=vocab_size, output_dim=embedding_size, name=\"encoder_embedding\"\n",")(encoder_inputs)\n","encoder_outputs, state_h, state_c = LSTM(128, return_state=True, name=\"encoder_lstm\")(\n","    encoder_embedding\n",")\n","encoder_states = [state_h, state_c]\n","\n","# decoder\n","decoder_inputs = Input(\n","    shape=(decoder_seq_length,), dtype=\"int32\", name=\"decoder_inputs\"\n",")\n","decoder_embedding = Embedding(\n","    input_dim=vocab_size, output_dim=embedding_size, name=\"decoder_embedding\"\n",")(decoder_inputs)\n","decoder_lstm = LSTM(128, return_sequences=True, return_state=True, name=\"decoder_lstm\")\n","decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n","decoder_dense = TimeDistributed(\n","    Dense(vocab_size, activation=\"softmax\", name=\"decoder_dense\")\n",")\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","model.compile(\n","    optimizer=\"nadam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",")"]},{"cell_type":"code","execution_count":117,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":151,"status":"ok","timestamp":1709941378861,"user":{"displayName":"Qilin Zhou","userId":"10885857608007718413"},"user_tz":360},"id":"LOZH1ik5OT79","outputId":"d14e3017-eb01-4ff8-b36f-38834607def2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_11\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," encoder_inputs (InputLayer  [(None, 18)]                 0         []                            \n"," )                                                                                                \n","                                                                                                  \n"," decoder_inputs (InputLayer  [(None, 12)]                 0         []                            \n"," )                                                                                                \n","                                                                                                  \n"," encoder_embedding (Embeddi  (None, 18, 32)               1184      ['encoder_inputs[0][0]']      \n"," ng)                                                                                              \n","                                                                                                  \n"," decoder_embedding (Embeddi  (None, 12, 32)               1184      ['decoder_inputs[0][0]']      \n"," ng)                                                                                              \n","                                                                                                  \n"," encoder_lstm (LSTM)         [(None, 128),                82432     ['encoder_embedding[0][0]']   \n","                              (None, 128),                                                        \n","                              (None, 128)]                                                        \n","                                                                                                  \n"," decoder_lstm (LSTM)         [(None, 12, 128),            82432     ['decoder_embedding[0][0]',   \n","                              (None, 128),                           'encoder_lstm[0][1]',        \n","                              (None, 128)]                           'encoder_lstm[0][2]']        \n","                                                                                                  \n"," time_distributed_4 (TimeDi  (None, 12, 37)               4773      ['decoder_lstm[0][0]']        \n"," stributed)                                                                                       \n","                                                                                                  \n","==================================================================================================\n","Total params: 172005 (671.89 KB)\n","Trainable params: 172005 (671.89 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"SAEk2x5zBcPO"},"source":["### Train the model"]},{"cell_type":"code","execution_count":118,"metadata":{"executionInfo":{"elapsed":133,"status":"ok","timestamp":1709941381323,"user":{"displayName":"Qilin Zhou","userId":"10885857608007718413"},"user_tz":360},"id":"CsAMkN3WIOge"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","(\n","    encoder_input_train,\n","    encoder_input_val,\n","    decoder_input_train,\n","    decoder_input_val,\n","    decoder_target_train,\n","    decoder_target_val,\n",") = train_test_split(\n","    encoder_input_data,\n","    decoder_input_data,\n","    decoder_target_data,\n","    test_size=0.2,\n","    random_state=42,\n",")"]},{"cell_type":"code","execution_count":119,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":207065,"status":"ok","timestamp":1709941589394,"user":{"displayName":"Qilin Zhou","userId":"10885857608007718413"},"user_tz":360},"id":"CmcO1uVbKkfS","outputId":"142d99d4-0422-4c31-e35e-73069e82b6bd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","250/250 [==============================] - 24s 76ms/step - loss: 1.3979 - accuracy: 0.5301 - val_loss: 0.9650 - val_accuracy: 0.6209\n","Epoch 2/10\n","250/250 [==============================] - 16s 66ms/step - loss: 0.9086 - accuracy: 0.6450 - val_loss: 0.8397 - val_accuracy: 0.6708\n","Epoch 3/10\n","250/250 [==============================] - 18s 71ms/step - loss: 0.7162 - accuracy: 0.7339 - val_loss: 0.5785 - val_accuracy: 0.8005\n","Epoch 4/10\n","250/250 [==============================] - 18s 73ms/step - loss: 0.4536 - accuracy: 0.8520 - val_loss: 0.3429 - val_accuracy: 0.8987\n","Epoch 5/10\n","250/250 [==============================] - 17s 67ms/step - loss: 0.2567 - accuracy: 0.9267 - val_loss: 0.1812 - val_accuracy: 0.9549\n","Epoch 6/10\n","250/250 [==============================] - 18s 70ms/step - loss: 0.1252 - accuracy: 0.9748 - val_loss: 0.0755 - val_accuracy: 0.9934\n","Epoch 7/10\n","250/250 [==============================] - 18s 73ms/step - loss: 0.0504 - accuracy: 0.9972 - val_loss: 0.0315 - val_accuracy: 0.9996\n","Epoch 8/10\n","250/250 [==============================] - 16s 66ms/step - loss: 0.0229 - accuracy: 0.9998 - val_loss: 0.0164 - val_accuracy: 1.0000\n","Epoch 9/10\n","250/250 [==============================] - 16s 66ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n","Epoch 10/10\n","250/250 [==============================] - 17s 67ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x7cdc6ee301f0>"]},"execution_count":119,"metadata":{},"output_type":"execute_result"}],"source":["model.fit(\n","    [encoder_input_train, decoder_input_train],\n","    np.expand_dims(decoder_target_train, -1),\n","    batch_size=64,\n","    epochs=10,\n","    validation_data=(\n","        [encoder_input_val, decoder_input_val],\n","        np.expand_dims(decoder_target_val, -1),\n","    ),\n",")"]},{"cell_type":"code","execution_count":120,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1709941589394,"user":{"displayName":"Qilin Zhou","userId":"10885857608007718413"},"user_tz":360},"id":"uptobgaYP8ht"},"outputs":[],"source":["char_to_token = tokenizer.word_index\n","token_to_char = {token_id: char for char, token_id in char_to_token.items()}\n","\n","\n","def prepare_input(input_date_str, tokenizer, max_encoder_seq_length):\n","    input_tokens = [char for char in input_date_str]\n","    input_token_ids = [tokenizer.word_index.get(token, 0) for token in input_tokens]\n","    padded_input_token_ids = pad_sequences(\n","        [input_token_ids], maxlen=max_encoder_seq_length, padding=\"post\"\n","    )\n","\n","    return padded_input_token_ids"]},{"cell_type":"code","execution_count":123,"metadata":{"executionInfo":{"elapsed":141,"status":"ok","timestamp":1709941636989,"user":{"displayName":"Qilin Zhou","userId":"10885857608007718413"},"user_tz":360},"id":"a_dC3_8aGLeu"},"outputs":[],"source":["def predict_date(\n","    model, input_date_str, tokenizer, max_encoder_seq_length, max_decoder_seq_length\n","):\n","    input_seq = prepare_input(input_date_str, tokenizer, max_encoder_seq_length)\n","\n","    sos_token_id = tokenizer.word_index[\"\\t\"]\n","    decoder_input_seq = np.zeros((1, max_decoder_seq_length))\n","    decoder_input_seq[0, 0] = sos_token_id\n","\n","    predicted_sequence = []\n","\n","    for i in range(1, max_decoder_seq_length):\n","        output_tokens = model.predict([input_seq, decoder_input_seq])\n","        sampled_token_index = np.argmax(output_tokens[0, i - 1, :])\n","        sampled_char = token_to_char.get(sampled_token_index)\n","\n","        if sampled_char == \"\\n\":\n","            break\n","        predicted_sequence.append(sampled_char)\n","\n","        decoder_input_seq[0, i] = sampled_token_index\n","\n","    return \"\".join(predicted_sequence)"]},{"cell_type":"code","execution_count":129,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1492,"status":"ok","timestamp":1709941721805,"user":{"displayName":"Qilin Zhou","userId":"10885857608007718413"},"user_tz":360},"id":"3iGYrXa6GlhR","outputId":"5540de91-fce1-4f52-ef15-018438b78828"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 48ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 40ms/step\n","Input date: April 19, 2019\n","Predicted date: 2019-04-19\n"]}],"source":["input_date_str = \"April 19, 2019\"\n","predicted_date = predict_date(\n","    model, input_date_str, tokenizer, max_encoder_seq_length, max_decoder_seq_length\n",")\n","print(f\"Input date: {input_date_str}\")\n","print(f\"Predicted date: {predicted_date}\")"]},{"cell_type":"markdown","metadata":{"id":"uBq8EyrrXc0t"},"source":["## Question 2: Use BERT or GPT-2 language models to generate more convincing Shakespearean text than what we did in the lecture."]},{"cell_type":"markdown","metadata":{"id":"d9qHAagNXyUK"},"source":["### Prepare Dataset"]},{"cell_type":"code","execution_count":164,"metadata":{"executionInfo":{"elapsed":140,"status":"ok","timestamp":1709946615653,"user":{"displayName":"Qilin Zhou","userId":"10885857608007718413"},"user_tz":360},"id":"UGOLjkhOX4nt"},"outputs":[],"source":["from tensorflow import keras\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel, pipeline"]},{"cell_type":"code","execution_count":159,"metadata":{"executionInfo":{"elapsed":170,"status":"ok","timestamp":1709946310296,"user":{"displayName":"Qilin Zhou","userId":"10885857608007718413"},"user_tz":360},"id":"uz7s6WLzXcM2"},"outputs":[],"source":["shakespeare_url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n","filepath = keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n","with open(filepath) as f:\n","    shakespeare_text = f.read()"]},{"cell_type":"markdown","metadata":{"id":"AZ4ZLCcNx4Ys"},"source":["### Adjusting pretrained GPT2 model to generate Shakespearean text"]},{"cell_type":"code","execution_count":167,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17635,"status":"ok","timestamp":1709946812730,"user":{"displayName":"Qilin Zhou","userId":"10885857608007718413"},"user_tz":360},"id":"zzjT2tWJewVA","outputId":"ce9eabfe-464a-4175-fdda-4a259be18e71"},"outputs":[{"name":"stdout","output_type":"stream","text":["Completed text 1: To be or not to be, that is the question: Is it worth spending your hard-earned money on a brand new car?\n","The answer for us here at DHL has been yes. We're still testing our own version of this concept in Europe and China so you can't expect much else from them â€“ but we'll continue checking out what's going into creating an authentic model based upon these latest prototypes!\n","\n","---\n","\n","Completed text 2: To be or not to be, that is the question: are you in love with your spouse? If so (or if I am and want nothing), will it change my life?\"\n","The answer seems pretty obvious. However a great many people who have been married for 20 years think this does seem quite strange at first glanceâ€¦ but how can they possibly know when their loved one has changed his/her mind from being happy on top of everything else about them?! They would probably find out because we\n","\n","---\n","\n","Completed text 3: To be or not to be, that is the question: Is it true? It depends upon how you measure.\n","The \"fact\" of God's existence does NOT have anything in common with its definition as a beingâ€”it has only an infinite number possibilities and therefore no real sense from which one can draw conclusions about what would constitute reality (i) â€”a fact called objective truth; but this conclusion may also include some other subjective truths such things do possess (\"truths\") when they are expressed\n","\n","---\n","\n","Completed text 4: To be or not to be, that is the question: Does a child really have all those things in his head? And there are some people who say no. But when you're talking about it like thisâ€”and even if we don't get an answer right away at every moment but I think many of us do and will soon realize what happens with kids just because they've got more than one thing on their mindsâ€”\"the way children grow out into adults has become so complicated.\"\n","\n","\n"," \"\n","\n","---\n","\n","Completed text 5: To be or not to be, that is the question: Who can I trust?\n","We will answer this by asking these questions. First of all we must ask a very simple matter-of who does what and for how long it takes us at least an hour each day just sitting in front on our computer screen looking out from their TV without having any idea where they are going (the game console). This information gives you your time as well as answers when things go wrong while still being able take\n","\n","---\n","\n","Completed text 6: To be or not to be, that is the question: what exactly does a man do when he comes home from work?\"\n",". And if you have ever been struck by lightning at your workplace - with an object falling down like butter into one of those black-andâ€‘white screens in front and everyone looking on horrifiedly as they watch it go through their minds for just seconds before exploding out upon itself without warning. But this was all over television last year; we didn't even notice until today\n","\n","---\n","\n"]}],"source":["model_name = \"gpt2\"\n","tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","model = GPT2LMHeadModel.from_pretrained(model_name)\n","\n","tokenizer.pad_token = tokenizer.eos_token\n","model.config.pad_token_id = tokenizer.eos_token_id\n","\n","\n","def generate_text(prompt_text, max_length=100, temperature=0.9, num_return_sequences=1):\n","    # Encode the prompt text with attention mask\n","    encoded_input = tokenizer(\n","        prompt_text,\n","        return_tensors=\"pt\",\n","        padding=True,\n","        truncation=True,\n","        max_length=max_length,\n","    )\n","    input_ids = encoded_input[\"input_ids\"]\n","    attention_mask = encoded_input[\"attention_mask\"]\n","\n","    output_sequences = model.generate(\n","        input_ids=input_ids,\n","        attention_mask=attention_mask,\n","        max_length=max_length,\n","        temperature=temperature,\n","        top_k=30,\n","        top_p=0.92,\n","        repetition_penalty=1.5,\n","        pad_token_id=tokenizer.eos_token_id,\n","        do_sample=True,\n","        num_return_sequences=num_return_sequences,\n","    )\n","\n","    generated_texts = [\n","        tokenizer.decode(output_sequence, skip_special_tokens=True)\n","        for output_sequence in output_sequences\n","    ]\n","\n","    return generated_texts\n","\n","\n","# Example usage\n","input_text = \"To be or not to be, that is the question:\"\n","completed_texts = generate_text(\n","    input_text, max_length=100, temperature=0.8, num_return_sequences=6\n",")\n","\n","for i, text in enumerate(completed_texts, 1):\n","    print(f\"Completed text {i}:\", text)\n","    print(\"\\n---\\n\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO9xCzJeHO1kDqCFk09v3ZM","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
